dLbase_1 = diff(c(0, cox_b1$cum_haz$cum_haz))
dL1 = dLbase_1 * exp(sum(c(za_iv, cal_level) * cox_b1$coeff))
n1_1 = my_eva_fun(list(cumsum(w1 * dL1), cox_b1$cum_haz$time), estimation_alpha$time, rule = '0')
}else{
n1_1 = rep(0, length(group_1_time))
}
counterfactual_hazard = n1_0 + n1_1
return(counterfactual_hazard)
}
estimate_effect = function(df, effect, intervention, cal_level, sen_ana, get_variance, boot_times, timer, num_of_cores, unique_T2, b0_time, b1_time, variance_method, threshold){
## beta part
# auxiliary
m = dim(df)[1]
n_col = dim(df)[2]
num_covariates = n_col - 4
covariates = as.matrix(df[, 4+1:num_covariates])
# b0
time_b0 = cbind(rep(0, m), df$T1)
observed_b0 = df$d2 & (df$d1 == FALSE)
cox_b0 = mycoxph(time_b0, observed_b0, covariates, get_variance)
# b1
df_b1 = df[df$d1, ]
time_b1 = df_b1[, c(1, 2)]
observed_b1 = df_b1$d2
cox_b1 = mycoxph(time_b1, observed_b1, as.matrix(covariates[df$d1, ]), get_variance)
# make it small
#-----------------------------------------------------------------------------------------------#
# small cox will be used while computing the covariance of alphas and the counterfactual hazard #
# cox will be used while computing the variance                                                 #
#-----------------------------------------------------------------------------------------------#
small_cox_b0 = make_small(cox_b0, b0_time)
small_cox_b1 = make_small(cox_b1, b1_time)
## alpha part
estimation_alpha = estimate_alpha(df, cal_level, small_cox_b0, small_cox_b1, unique_T2, get_variance, timer, num_of_cores, variance_method, threshold)
## get counterfactual hazard
AsymVariance = sum(c('a', 'A', 'asym', 'asymptotic', 'asymptotical', 'Asym', 'Asymptotic', 'Asymptotical') %in% get_variance) > 0
get_DE = sum(c('d', 'D', 'de', 'De', 'DE', 'direct effect', 'Direct effect', 'Direct Effect') %in% effect) > 0
get_IE = sum(c('i', 'I', 'ie', 'Ie', 'IE', 'indirect effect', 'Indirect effect', 'Indirect Effect') %in% effect) > 0
result = list()
## Direct effect
if(get_DE){
za_iv1 = intervention[1]; zb_iv1 = intervention[2]; za_iv2 = intervention[2]; zb_iv2 = intervention[2];
counterfactual_hazard_iv1 = get_counterfactual_hazard(za_iv1, zb_iv1, cal_level, estimation_alpha, small_cox_b0, small_cox_b1)
counterfactual_hazard_iv2 = get_counterfactual_hazard(za_iv2, zb_iv2, cal_level, estimation_alpha, small_cox_b0, small_cox_b1)
counterfactual_hazard = counterfactual_hazard_iv1 - counterfactual_hazard_iv2
weight = sqrt(estimation_alpha$sick_alive * estimation_alpha$healthy_alive)/estimation_alpha$alive
# result$DE$Q_stat = sum(counterfactual_hazard * weight) / sum(weight)
result$DE$effect = counterfactual_hazard
result$DE$time = estimation_alpha$time
if(AsymVariance){
result$DE$variance = compute_variance(get_DE = TRUE, get_IE = FALSE, intervention, cal_level, estimation_alpha, cox_b0, cox_b1, b0_time, b1_time)
result$DE$asym_lower = result$DE$effect - 1.96 * sqrt(result$DE$variance$variance)
result$DE$asym_upper = result$DE$effect + 1.96 * sqrt(result$DE$variance$variance)
}
if(sen_ana){result$DE$sensitivity_analysis = do_sen_ana(get_DE = TRUE, get_IE = FALSE, intervention, cal_level, estimation_alpha, small_cox_b0, small_cox_b1)}
}
## Indirect effect
if(get_IE){
za_iv1 = intervention[1]; zb_iv1 = intervention[1]; za_iv2 = intervention[1]; zb_iv2 = intervention[2];
counterfactual_hazard_iv1 = get_counterfactual_hazard(za_iv1, zb_iv1, cal_level, estimation_alpha, small_cox_b0, small_cox_b1)
counterfactual_hazard_iv2 = get_counterfactual_hazard(za_iv2, zb_iv2, cal_level, estimation_alpha, small_cox_b0, small_cox_b1)
counterfactual_hazard = counterfactual_hazard_iv1 - counterfactual_hazard_iv2
weight = sqrt(estimation_alpha$sick_alive * estimation_alpha$healthy_alive)/estimation_alpha$alive
# result$IE$Q_stat = sum(counterfactual_hazard * weight) / sum(weight)
result$IE$effect = counterfactual_hazard
result$IE$time = estimation_alpha$time
if(AsymVariance){
result$IE$variance = compute_variance(get_DE = FALSE, get_IE = TRUE, intervention, cal_level, estimation_alpha, cox_b0, cox_b1)
result$IE$asym_lower = result$IE$effect - 1.96 * sqrt(result$IE$variance$variance)
result$IE$asym_upper = result$IE$effect + 1.96 * sqrt(result$IE$variance$variance)
}
if(sen_ana){result$IE$sensitivity_analysis = do_sen_ana(get_DE = FALSE, get_IE = TRUE, intervention, cal_level, estimation_alpha, small_cox_b0, small_cox_b1)}
}
result$alive = estimation_alpha$alive
result$healthy_alive = estimation_alpha$healthy_alive
result$sick_alive = estimation_alpha$sick_alive
result$converged_alpha = estimation_alpha$converged_alpha
result$alpha = estimation_alpha$coeff
result$cox_b0 = list(coeff = cox_b0$coeff, cum_haz = cox_b0$cum_haz)
result$cox_b1 = list(coeff = cox_b1$coeff, cum_haz = cox_b1$cum_haz)
return(result)
}
## plot function
plot_poly = function(y1, y2, x, color, density = NULL, angle = NULL){
# y1 = df_asymp_DE$lower; y2 = df_asymp_DE$upper; x = df_asymp_DE$time; color = "dodgerblue"
yy1 = c(rep(y1, each = 2)); yy1 = yy1[1:(length(yy1) - 1)]
yy2 = c(rep(y2, each = 2)); yy2 = rev(yy2[1:(length(yy2)) - 1])
xx = rep(x, each = 2); xx = xx[2:length(xx)]
polygon(y = c(yy1, yy2), x = c(xx, rev(xx)), density = density, col = adjustcolor(color, alpha.f = 0.3), border = color, angle = angle)
}
plot_CHH2020 = function(result){
result$IE$time = result$IE$time / 365.25
result$DE$time = result$DE$time / 365.25
ylim_cumh_upper = max(result$IE$boot_upper, result$DE$boot_upper, result$IE$asym_upper, result$DE$asym_upper)
ylim_cumh_lower = min(result$IE$boot_lower, result$DE$boot_lower, result$IE$asym_lower, result$DE$asym_lower)
ylim_surv_lower = exp(-ylim_cumh_upper)
ylim_surv_upper = exp(-ylim_cumh_lower)
## plot default
cex.lab = 1.1
cex.main = 1.1
cex.axis = 1
las = 1
xlab = 'Time (years)'
ylab_rho = expression(paste(rho[DE](t), ',', rho[IE](t)))
ylab_Del = expression(paste(Delta[DE](t), ',', Delta[IE](t)))
## bootstrap, surv
df_asymp_IE = data.frame(cumhaz = exp(-result$IE$effect), time = result$IE$time, upper = exp(-result$IE$boot_upper), lower = exp(-result$IE$boot_lower))
df_asymp_DE = data.frame(cumhaz = exp(-result$DE$effect), time = result$DE$time, upper = exp(-result$DE$boot_upper), lower = exp(-result$DE$boot_lower))
plot(cumhaz ~ time, data = df_asymp_IE, type = "s", lwd = 2, ylim = c(ylim_surv_lower, ylim_surv_upper), col = adjustcolor("orange", alpha.f = 0.50), main = "Survival probability ratio \n Bootstrap CI", xlab = xlab, ylab = ylab_rho, cex.lab = cex.lab, cex.main = cex.main, cex.axis = cex.axis, las = las)
lines(cumhaz ~ time, data = df_asymp_DE, type = "s", lwd = 2, col = adjustcolor("dodgerblue", alpha.f = 0.50))
legend("bottomleft", legend = c("Indirect effct", "Direct effect"), fill = c(adjustcolor("orange", alpha.f = 0.10), adjustcolor("dodgerblue", alpha.f = 0.10)), bty = "n", border = c(adjustcolor("orange", alpha.f = 10), adjustcolor("dodgerblue", alpha.f = 10)))
plot_poly(df_asymp_DE$lower, df_asymp_DE$upper, df_asymp_DE$time, "dodgerblue", NULL)
plot_poly(df_asymp_IE$lower, df_asymp_IE$upper, df_asymp_IE$time, "orange", NULL)
abline(h = 1, col = "grey")
## bootstrap, hazard
df_asymp_IE = data.frame(cumhaz = result$IE$effect, time = result$IE$time, upper = result$IE$boot_upper, lower = result$IE$boot_lower)
df_asymp_DE = data.frame(cumhaz = result$DE$effect, time = result$DE$time, upper = result$DE$boot_upper, lower = result$DE$boot_lower)
plot(cumhaz ~ time, data = df_asymp_IE, type = "s", lwd = 2, ylim = c(ylim_cumh_lower, ylim_cumh_upper), col = adjustcolor("orange", alpha.f = 0.50), main = "Cumulative hazard difference \n Bootstrap CI",  xlab = xlab, ylab = ylab_Del, cex.lab = cex.lab, cex.main = cex.main, cex.axis = cex.axis, las = las)
lines(cumhaz ~ time, data = df_asymp_DE, type = "s", lwd = 2, col = adjustcolor("dodgerblue", alpha.f = 0.50))
legend("topleft", legend = c("Indirect effct", "Direct effect"), cex = 0.85, fill = c(adjustcolor("orange", alpha.f = 0.10), adjustcolor("dodgerblue", alpha.f = 0.10)), bty = "n", border = c(adjustcolor("orange", alpha.f = 10), adjustcolor("dodgerblue", alpha.f = 10)))
plot_poly(df_asymp_DE$lower, df_asymp_DE$upper, df_asymp_DE$time, "dodgerblue", NULL)
plot_poly(df_asymp_IE$lower, df_asymp_IE$upper, df_asymp_IE$time, "orange", NULL)
abline(h = 0, col = "grey")
## asymptotic, surv
df_asymp_IE = data.frame(cumhaz = exp(-result$IE$effect), time = result$IE$time, upper = exp(-result$IE$asym_upper), lower = exp(-result$IE$asym_lower))
df_asymp_DE = data.frame(cumhaz = exp(-result$DE$effect), time = result$DE$time, upper = exp(-result$DE$asym_upper), lower = exp(-result$DE$asym_lower))
plot(cumhaz ~ time, data = df_asymp_IE, type = "s", lwd = 2, ylim = c(ylim_surv_lower, ylim_surv_upper), col = adjustcolor("orange", alpha.f = 0.50), main = "Survival probability ratio \n Asymptotic CI",  xlab = xlab, ylab = ylab_rho, cex.lab = cex.lab, cex.main = cex.main, cex.axis = cex.axis, las = las)
lines(cumhaz ~ time, data = df_asymp_DE, type = "s", lwd = 2, col = adjustcolor("dodgerblue", alpha.f = 0.50))
legend("bottomleft", legend = c("Indirect effct", "Direct effect"), cex = 0.85, fill = c(adjustcolor("orange", alpha.f = 0.10), adjustcolor("dodgerblue", alpha.f = 0.10)), bty = "n", border = c(adjustcolor("orange", alpha.f = 10), adjustcolor("dodgerblue", alpha.f = 10)))
plot_poly(df_asymp_DE$lower, df_asymp_DE$upper, df_asymp_DE$time, "dodgerblue", NULL)
plot_poly(df_asymp_IE$lower, df_asymp_IE$upper, df_asymp_IE$time, "orange", NULL)
abline(h = 1, col = "grey")
## asymptotic, hazard
df_asymp_IE = data.frame(cumhaz = result$IE$effect, time = result$IE$time, upper = result$IE$asym_upper, lower = result$IE$asym_lower)
df_asymp_DE = data.frame(cumhaz = result$DE$effect, time = result$DE$time, upper = result$DE$asym_upper, lower = result$DE$asym_lower)
plot(cumhaz ~ time, data = df_asymp_IE, type = "s", lwd = 2, ylim = c(ylim_cumh_lower, ylim_cumh_upper), col = adjustcolor("orange", alpha.f = 0.50), main = "Cumulative hazard difference \n Asymptotic CI", xlab = xlab, ylab = ylab_Del, cex.lab = cex.lab, cex.main = cex.main, cex.axis = cex.axis, las = las)
lines(cumhaz ~ time, data = df_asymp_DE, type = "s", lwd = 2, col = adjustcolor("dodgerblue", alpha.f = 0.50))
legend("topleft", legend = c("Indirect effct", "Direct effect"), cex = 0.85, fill = c(adjustcolor("orange", alpha.f = 0.10), adjustcolor("dodgerblue", alpha.f = 0.10)), bty = "n", border = c(adjustcolor("orange", alpha.f = 10), adjustcolor("dodgerblue", alpha.f = 10)))
plot_poly(df_asymp_DE$lower, df_asymp_DE$upper, df_asymp_DE$time, "dodgerblue", NULL)
plot_poly(df_asymp_IE$lower, df_asymp_IE$upper, df_asymp_IE$time, "orange", NULL)
abline(h = 0, col = "grey")
return(TRUE)
}
plot_unbiasedness = function(result_, true_, ylim, hypo, effect, confounder, calibration){
# result_ = result_IE$FF; true_ = true_IE; ylim = min_max_IE; effect = 'IE'; confounder = F; calibration = F;
# result_ = result_DE$FF; true_ = true_DE; effect = "DE"; calibration = F; ylim = min_max_DE;
cex.lab = 2
cex.main = 2.5
cex.axis = 1.5
if(confounder == FALSE){
main = paste("No confounding \n", effect, ', ', hypo, sep = '')
}else{
if(calibration == FALSE){
main = paste("Confounding, unadjusted \n", effect, ', ', hypo, sep = '')
}else{
main = paste("Confounding, adjusted \n", effect, ', ', hypo, sep = '')
}
}
xlab = "Time"
if(effect == "DE"){
ylab = expression(Delta[DE](t))
}else{
ylab = expression(Delta[IE](t))
}
time_axis = seq(0, 2.5, 0.01)
index_all = NULL
ave_DE = rep(0, length(time_axis))
plot(NULL, xlim = c(0, 3), ylim = ylim, xlab = xlab, ylab = '', main = main, cex.lab = cex.lab, cex.main = cex.main, cex.axis = cex.axis)
title(ylab = ylab, line = 2.2, cex.lab = cex.lab)
for(i in 1:length(result_)){
ave_DE = ave_DE + approx(result_[[i]]$time, result_[[i]]$effect, xout = time_axis, method = 'constant', rule = 2)$y
lines(result_[[i]]$time, result_[[i]]$effect, col = 'grey', lwd = .5, type = 's')
index_all = c(index_all, floor(result_[[i]]$sick * 1000))
}
index_all = sort(index_all)
time_slot = approx(x = index_all, y = 1:length(index_all), xout = unique(index_all), ties = "max", rule = 2, method = "constant")
time_slot$y = c(time_slot$y[1], diff(time_slot$y))
small_line = c(ylim[1], ylim[1] + (ylim[2] - ylim[1]) / 15)
for(i in 1:length(time_slot$x)){
lines(rep(0.001 * i, 2), small_line, lwd = time_slot$y[i]/max(time_slot$y))
}
legend(x = 0, y = ylim[1] + 4 * (ylim[2] - ylim[1]) / 15, legend = c("Average", "True Value"), cex = 1.5, lty = c(1, 2))
ave_DE = ave_DE/length(result_)
lines(time_axis, ave_DE, type = 's', lty = 1, lwd = 2)
lines(true_$time, true_$hazard, type = 's', lty = 2, lwd = 2)
}
alternative_z_1_2 = function(hypo, effect, confounder, intervention){
tstart = 0
tend = 5
t = seq(tstart, tend, by = 1e-4)
diff_t = t[2] - t[1]
alpha1Z = 0.25 * (hypo == 'alter')
alpha2Z = 0.25 * (hypo == 'alter')
alphaX = 1 * confounder * 0.5
intersection = -0
#### (2, 2)
z_a = intervention[1]
z_b = ifelse(effect == 'DE', intervention[2], intervention[1])
a1zb = exp(intersection + alpha1Z * z_b + alphaX)
ca2zb = 0.5 * exp(alpha2Z * z_b + alphaX)
ca2za = 0.5 * exp(alpha2Z * z_a + alphaX)
w0_numerator = exp(-t / a1zb)
w0_denominator = 1/(a1zb - ca2zb) * (a1zb * exp(-t / a1zb) - ca2zb * exp(-t / ca2zb))
w1 = 1 - w0_numerator/w0_denominator
case1 = cumsum(w1) * diff_t / ca2za
#### (2, 1)
z_a = ifelse(effect == 'DE', intervention[2], intervention[1])
z_b = intervention[2]
a1zb = exp(intersection + alpha1Z * z_b + alphaX)
ca2zb = 0.5 * exp(alpha2Z * z_b + alphaX)
ca2za = 0.5 * exp(alpha2Z * z_a + alphaX)
w0_numerator = exp(-t / a1zb)
w0_denominator = 1/(a1zb - ca2zb) * (a1zb * exp(-t / a1zb) - ca2zb * exp(-t / ca2zb))
w1 = 1 - w0_numerator/w0_denominator
case2 = cumsum(w1) * diff_t / ca2za
#### (2, 2) - (2, 1)
cumhaz = data.frame(hazard = case1 - case2, time = t)
return(cumhaz)
}
alternative_z_1_2 = function(hypo, effect, confounder, intervention){
tstart = 0
tend = 4
t = seq(tstart, tend, by = 5e-4)
diff_t = t[2] - t[1]
alpha1Z = 0.25 * (hypo == 'alter')
alpha2Z = 0.25 * (hypo == 'alter')
alphaX = 1 * confounder * 0.5
intersection = -0
#### (2, 2)
z_a = intervention[1]
z_b = ifelse(effect == 'DE', intervention[2], intervention[1])
a1zb = exp(intersection + alpha1Z * z_b + alphaX)
ca2zb = 0.5 * exp(alpha2Z * z_b + alphaX)
ca2za = 0.5 * exp(alpha2Z * z_a + alphaX)
w0_numerator = exp(-t / a1zb)
w0_denominator = 1/(a1zb - ca2zb) * (a1zb * exp(-t / a1zb) - ca2zb * exp(-t / ca2zb))
w1 = 1 - w0_numerator/w0_denominator
case1 = cumsum(w1) * diff_t / ca2za
#### (2, 1)
z_a = ifelse(effect == 'DE', intervention[2], intervention[1])
z_b = intervention[2]
a1zb = exp(intersection + alpha1Z * z_b + alphaX)
ca2zb = 0.5 * exp(alpha2Z * z_b + alphaX)
ca2za = 0.5 * exp(alpha2Z * z_a + alphaX)
w0_numerator = exp(-t / a1zb)
w0_denominator = 1/(a1zb - ca2zb) * (a1zb * exp(-t / a1zb) - ca2zb * exp(-t / ca2zb))
w1 = 1 - w0_numerator/w0_denominator
case2 = cumsum(w1) * diff_t / ca2za
#### (2, 2) - (2, 1)
cumhaz = data.frame(hazard = case1 - case2, time = t)
return(cumhaz)
}
alternative_z_1_2 = function(hypo, effect, confounder, intervention){
tstart = 0
tend = 4
t = seq(tstart, tend, by = 5e-4)
diff_t = t[2] - t[1]
alpha1Z = 0.25 * (hypo == 'alter')
alpha2Z = 0.25 * (hypo == 'alter')
alphaX = 1 * confounder * 0.5
intersection = -0
#### (2, 2)
z_a = intervention[1]
z_b = ifelse(effect == 'DE', intervention[2], intervention[1])
a1zb = exp(intersection + alpha1Z * z_b + alphaX)
ca2zb = 0.5 * exp(alpha2Z * z_b + alphaX)
ca2za = 0.5 * exp(alpha2Z * z_a + alphaX)
w0_numerator = exp(-t / a1zb)
w0_denominator = 1/(a1zb - ca2zb) * (a1zb * exp(-t / a1zb) - ca2zb * exp(-t / ca2zb))
w1 = 1 - w0_numerator/w0_denominator
case1 = cumsum(w1) * diff_t / ca2za
#### (2, 1)
z_a = ifelse(effect == 'DE', intervention[2], intervention[1])
z_b = intervention[2]
a1zb = exp(intersection + alpha1Z * z_b + alphaX)
ca2zb = 0.5 * exp(alpha2Z * z_b + alphaX)
ca2za = 0.5 * exp(alpha2Z * z_a + alphaX)
w0_numerator = exp(-t / a1zb)
w0_denominator = 1/(a1zb - ca2zb) * (a1zb * exp(-t / a1zb) - ca2zb * exp(-t / ca2zb))
w1 = 1 - w0_numerator/w0_denominator
case2 = cumsum(w1) * diff_t / ca2za
#### (2, 2) - (2, 1)
cumhaz = data.frame(hazard = case1 - case2, time = t)
return(cumhaz)
}
hypo = 'alter'
sample_size = 1000
# sample_size = 1000
# hypo = 'null'
# num_of_cores = 40
# timer = TRUE
repeat_size = 1000
# sample_size = 1000
# hypo = 'null'
num_of_cores = 10
# sample_size = 1000
# hypo = 'null'
# num_of_cores = 10
timer = TRUE
coverage_rate = coverage(hypo, sample_size, repeat_size, num_of_cores, timer = TRUE, get_variance = c('a', 'b1'))
coverage_rate
hypo
sample_size
sample_size = 300
repeat_size
coverage_rate = coverage(hypo, sample_size, repeat_size, num_of_cores, timer = TRUE, get_variance = c('a', 'b'))
num_of_cores = 12
coverage_rate = coverage(hypo, sample_size, repeat_size, num_of_cores, timer = TRUE, get_variance = c('a', 'b'))
coverage_rate
hypo = 'null'
coverage_rate = coverage(hypo, sample_size, repeat_size, num_of_cores, timer = TRUE, get_variance = c('a', 'b'))
coverage_rate
unbiasedness = function(hypo, sample_size, repeat_size, num_of_cores = 1, timer = TRUE){
result_DE = list()
result_DE$FF = vector(mode = "list", length = repeat_size)
result_DE$TF = vector(mode = "list", length = repeat_size)
result_DE$TT = vector(mode = "list", length = repeat_size)
result_IE = list()
result_IE$FF = vector(mode = "list", length = repeat_size)
result_IE$TF = vector(mode = "list", length = repeat_size)
result_IE$TT = vector(mode = "list", length = repeat_size)
min_max_DE = c(0, 0)
min_max_IE = c(0, 0)
if(num_of_cores > 1){
require(foreach)
## num_of_cores set-up
cores = num_of_cores
cl = snow::makeCluster(cores[1])
my_functions = c("CHH2020", "generate_df", "generate_df2", "alternative_z_1_2", "downsample_func", "data_preprocess", "df_shift_to_cal_level", "do_sen_ana", "estimate_alpha", "estimate_effect", "form_matrix", "get_alpha_variance", "get_beta_variance", "get_counterfactual_hazard", "get_pd", "get_position", "compute_variance", "inv_coxinformation", "make_small", "my_basehaz", "my_eva_fun", "my_sort_mat", "mycoxph", "rep.row")
snow::clusterExport(cl, my_functions)
doSNOW::registerDoSNOW(cl)
pb = txtProgressBar(max = repeat_size, style = 3)
progress = function(n) setTxtProgressBar(pb, n)
opts = list(progress = progress)
i = 1
result_now = foreach(i = 1:repeat_size, .options.snow = opts, .combine = 'c', .export = my_functions)%dopar%{
df_FF = generate_df(sample_size, repeat_size = 1, hypo, confounder = F, calibration = F, myseed = i)
df_TF = generate_df(sample_size, repeat_size = 1, hypo, confounder = T, calibration = F, myseed = i)
df_TT = generate_df(sample_size, repeat_size = 1, hypo, confounder = T, calibration = T, myseed = i)
result_FF = CHH2020(df_FF[[1]], get_variance = NULL, timer = FALSE, intervention = c(2, 1))
result_TF = CHH2020(df_TF[[1]], get_variance = NULL, timer = FALSE, intervention = c(2, 1))
result_TT = CHH2020(df_TT[[1]], get_variance = NULL, timer = FALSE, intervention = c(2, 1))
result_now = list(result_FF = result_FF, result_TF = result_TF, result_TT = result_TT)
gc()
return(list(result_now))
}
snow::stopCluster(cl)
pracma::fprintf('\n')
for(i in 1:repeat_size){
result_DE$FF[[i]]$time   = result_now[[i]][[1]]$DE$time
result_DE$FF[[i]]$effect = result_now[[i]][[1]]$DE$effect
result_DE$FF[[i]]$sick   = result_now[[i]][[1]]$cox_b1$cum_haz$time
result_DE$TF[[i]]$time   = result_now[[i]][[2]]$DE$time
result_DE$TF[[i]]$effect = result_now[[i]][[2]]$DE$effect
result_DE$TF[[i]]$sick   = result_now[[i]][[2]]$cox_b1$cum_haz$time
result_DE$TT[[i]]$time   = result_now[[i]][[3]]$DE$time
result_DE$TT[[i]]$effect = result_now[[i]][[3]]$DE$effect
result_DE$TT[[i]]$sick   = result_now[[i]][[3]]$cox_b1$cum_haz$time
result_IE$FF[[i]]$time   = result_now[[i]][[1]]$IE$time
result_IE$FF[[i]]$effect = result_now[[i]][[1]]$IE$effect
result_IE$FF[[i]]$sick   = result_now[[i]][[1]]$cox_b1$cum_haz$time
result_IE$TF[[i]]$time   = result_now[[i]][[2]]$IE$time
result_IE$TF[[i]]$effect = result_now[[i]][[2]]$IE$effect
result_IE$TF[[i]]$sick   = result_now[[i]][[2]]$cox_b1$cum_haz$time
result_IE$TT[[i]]$time   = result_now[[i]][[3]]$IE$time
result_IE$TT[[i]]$effect = result_now[[i]][[3]]$IE$effect
result_IE$TT[[i]]$sick   = result_now[[i]][[3]]$cox_b1$cum_haz$time
min_max_DE[1] = min(min_max_DE[1], result_DE$FF[[i]]$effect, result_DE$TF[[i]]$effect, result_DE$TT[[i]]$effect)
min_max_DE[2] = max(min_max_DE[2], result_DE$FF[[i]]$effect, result_DE$TF[[i]]$effect, result_DE$TT[[i]]$effect)
min_max_IE[1] = min(min_max_IE[1], result_IE$FF[[i]]$effect, result_IE$TF[[i]]$effect, result_IE$TT[[i]]$effect)
min_max_IE[2] = max(min_max_IE[2], result_IE$FF[[i]]$effect, result_IE$TF[[i]]$effect, result_IE$TT[[i]]$effect)
}
}else{
## fetch basic parameter
if(timer){
space = 100
pracma::fprintf('| bootstrap        20        30        40        50        60        70        80        90    100 |\n')
loop_count = 1:repeat_size
counter_total = repeat_size
cum_bar_num = my_eva_fun(list(1:space, 1:space / space * counter_total), loop_count, rule = '0')
bar_num = diff(c(0, cum_bar_num))
}
i = 1
for(i in 1:repeat_size){
# print(i)
df_FF = generate_df(sample_size, repeat_size = 1, hypo, confounder = F, calibration = F, myseed = i)
df_TF = generate_df(sample_size, repeat_size = 1, hypo, confounder = T, calibration = F, myseed = i)
df_TT = generate_df(sample_size, repeat_size = 1, hypo, confounder = T, calibration = T, myseed = i)
result_FF = CHH2020(df_FF[[1]], get_variance = NULL, timer = FALSE, intervention = c(2, 1))
result_TF = CHH2020(df_TF[[1]], get_variance = NULL, timer = FALSE, intervention = c(2, 1))
result_TT = CHH2020(df_TT[[1]], get_variance = NULL, timer = FALSE, intervention = c(2, 1))
result_DE$FF[[i]]$time   = result_FF$DE$time
result_DE$FF[[i]]$effect = result_FF$DE$effect
result_DE$FF[[i]]$sick   = result_FF$cox_b1$cum_haz$time
result_DE$TF[[i]]$time   = result_TF$DE$time
result_DE$TF[[i]]$effect = result_TF$DE$effect
result_DE$TF[[i]]$sick   = result_TF$cox_b1$cum_haz$time
result_DE$TT[[i]]$time   = result_TT$DE$time
result_DE$TT[[i]]$effect = result_TT$DE$effect
result_DE$TT[[i]]$sick   = result_TT$cox_b1$cum_haz$time
result_IE$FF[[i]]$time   = result_FF$IE$time
result_IE$FF[[i]]$effect = result_FF$IE$effect
result_IE$FF[[i]]$sick   = result_FF$cox_b1$cum_haz$time
result_IE$TF[[i]]$time   = result_TF$IE$time
result_IE$TF[[i]]$effect = result_TF$IE$effect
result_IE$TF[[i]]$sick   = result_TF$cox_b1$cum_haz$time
result_IE$TT[[i]]$time   = result_TT$IE$time
result_IE$TT[[i]]$effect = result_TT$IE$effect
result_IE$TT[[i]]$sick   = result_TT$cox_b1$cum_haz$time
min_max_DE[1] = min(min_max_DE[1], result_DE$FF[[i]]$effect, result_DE$TF[[i]]$effect, result_DE$TT[[i]]$effect)
min_max_DE[2] = max(min_max_DE[2], result_DE$FF[[i]]$effect, result_DE$TF[[i]]$effect, result_DE$TT[[i]]$effect)
min_max_IE[1] = min(min_max_IE[1], result_IE$FF[[i]]$effect, result_IE$TF[[i]]$effect, result_IE$TT[[i]]$effect)
min_max_IE[2] = max(min_max_IE[2], result_IE$FF[[i]]$effect, result_IE$TF[[i]]$effect, result_IE$TT[[i]]$effect)
if(timer && bar_num[i] > 0){for(i in 1:bar_num[i]){pracma::fprintf('-')}}
}
if(timer){pracma::fprintf('\n')}
}
width = 500
height = 500
# png(file = paste("/Users/js/Desktop/CHH2020/bias_DE_", hypo, "_no_conf.png", sep = ''), width = width, height = height)
true_DE = alternative_z_1_2(hypo, effect = 'DE', confounder = F, intervention = c(2, 1))
plot_successful = plot_unbiasedness(result_DE$FF, true_DE, ylim = min_max_DE, hypo, effect = 'DE', confounder = F, calibration = F)
# dev.off()
# png(file = paste("/Users/js/Desktop/CHH2020/bias_DE_", hypo, "_unadj_conf.png", sep = ''), width = width, height = height)
true_DE = alternative_z_1_2(hypo, effect = 'DE', confounder = T, intervention = c(2, 1))
plot_successful = plot_unbiasedness(result_DE$TF, true_DE, ylim = min_max_DE, hypo, effect = 'DE', confounder = T, calibration = F)
# dev.off()
# png(file = paste("/Users/js/Desktop/CHH2020/bias_DE_", hypo, "_adj_conf.png", sep = ''), width = width, height = height)
true_DE = alternative_z_1_2(hypo, effect = 'DE', confounder = T, intervention = c(2, 1))
plot_successful = plot_unbiasedness(result_DE$TT, true_DE, ylim = min_max_DE, hypo, effect = 'DE', confounder = T, calibration = T)
# dev.off()
if(hypo == "null"){
min_max_IE = c(-0.5, 0.5)
}else{
min_max_IE = c(-0.6, 0.3)
}
true_IE = alternative_z_1_2(hypo, effect = 'IE', confounder = F, intervention = c(2, 1))
# png(file = paste("/Users/js/Desktop/CHH2020/bias_IE_", hypo, "_no_conf.png", sep = ''), width = width, height = height)
plot_successful = plot_unbiasedness(result_IE$FF, true_IE, ylim = min_max_IE, hypo, effect = 'IE', confounder = F, calibration = F)
# dev.off()
true_IE = alternative_z_1_2(hypo, effect = 'IE', confounder = T, intervention = c(2, 1))
# png(file = paste("/Users/js/Desktop/CHH2020/bias_IE_", hypo, "_unadj_conf.png", sep = ''), width = width, height = height)
plot_successful = plot_unbiasedness(result_IE$TF, true_IE, ylim = min_max_IE, hypo, effect = 'IE', confounder = T, calibration = F)
# dev.off()
true_IE = alternative_z_1_2(hypo, effect = 'IE', confounder = T, intervention = c(2, 1))
# png(file = paste("/Users/js/Desktop/CHH2020/bias_IE_", hypo, "_adj_conf.png", sep = ''), width = width, height = height)
plot_successful = plot_unbiasedness(result_IE$TT, true_IE, ylim = min_max_IE, hypo, effect = 'IE', confounder = T, calibration = T)
# dev.off()
return(TRUE)
}
devtools::document()
devtools::install()
devtools::install_github("JuShengHong/CausalAnalysisforSemiCompRisks")
load(file = "data/REVEAL_HBV.rda")
result = CHH2020(REVEAL_HBV, downsample = 20, plot_result = T, get_variance = c('a', 'b'), boot_times = 100)
simulation(1, 'null', repeat_size = 100, num_of_cores = 10)
get(name, envir = envir)
get()
simulation(2, 'null', repeat_size = 100, num_of_cores = 10)
my_functions = c("CHH2020", "generate_df", "generate_df2", "alternative_z_1_2", "downsample_func", "data_preprocess", "df_shift_to_cal_level", "do_sen_ana", "estimate_alpha", "estimate_effect", "form_matrix", "get_alpha_variance", "get_beta_variance", "get_counterfactual_hazard", "get_pd", "get_position", "compute_variance", "inv_coxinformation", "make_small", "my_basehaz", "my_eva_fun", "my_sort_mat", "mycoxph", "rep.row")
cl = snow::makeCluster(cores[1])
num_of_cores = 10
## num_of_cores set-up
cores = num_of_cores
cl = snow::makeCluster(cores[1])
my_functions = c("CHH2020", "generate_df", "generate_df2", "alternative_z_1_2", "downsample_func", "data_preprocess", "df_shift_to_cal_level", "do_sen_ana", "estimate_alpha", "estimate_effect", "form_matrix", "get_alpha_variance", "get_beta_variance", "get_counterfactual_hazard", "get_pd", "get_position", "compute_variance", "inv_coxinformation", "make_small", "my_basehaz", "my_eva_fun", "my_sort_mat", "mycoxph", "rep.row")
snow::clusterExport(cl, my_functions)
result = CHH2020(REVEAL_HBV, downsample = 20, plot_result = T, get_variance = c('a', 'b'), boot_times = 100, num_of_cores = 10)
ls(parent.env())
ls(globalenv())
ls(environment())
devtools::document()
devtools::document()
devtools::install()
devtools::install_github("JuShengHong/CausalAnalysisforSemiCompRisks")
library(CausalAnalysisforSemiCompRisks)
load(file = "data/REVEAL_HBV.rda")
result = CHH2020(REVEAL_HBV, downsample = 20, plot_result = T, get_variance = c('a', 'b'), boot_times = 100, num_of_cores = 10)
devtools::document()
devtools::install()
devtools::install_github("JuShengHong/CausalAnalysisforSemiCompRisks")
library(CausalAnalysisforSemiCompRisks)
result = CHH2020(REVEAL_HBV, downsample = 20, plot_result = T, get_variance = c('a', 'b'), boot_times = 100, num_of_cores = 10)
devtools::document()
devtools::install()
devtools::install_github("JuShengHong/CausalAnalysisforSemiCompRisks")
library(CausalAnalysisforSemiCompRisks)
load(file = "data/REVEAL_HBV.rda")
result = CHH2020(REVEAL_HBV, downsample = 20, plot_result = T, get_variance = c('a', 'b'), boot_times = 100, num_of_cores = 10)
simulation(1, 'null', repeat_size = 100, num_of_cores = 10)
devtools::document()
devtools::install()
devtools::install_github("JuShengHong/CausalAnalysisforSemiCompRisks")
library(CausalAnalysisforSemiCompRisks)
load(file = "data/REVEAL_HBV.rda")
simulation(1, 'null', repeat_size = 100, num_of_cores = 10)
devtools::install()
devtools::install_github("JuShengHong/CausalAnalysisforSemiCompRisks")
library(CausalAnalysisforSemiCompRisks)
simulation(1, 'null', repeat_size = 100, num_of_cores = 10)
devtools::install()
devtools::install_github("JuShengHong/CausalAnalysisforSemiCompRisks")
library(CausalAnalysisforSemiCompRisks)
simulation(1, 'null', repeat_size = 100)
simulation(1, 'null', repeat_size = 100)
result = CHH2020(REVEAL_HBV, downsample = 20, plot_result = T, get_variance = c('a', 'b'))
remove.packages("CausalAnalysisforSemiCompRisks")
devtools::install_github("JuShengHong/CausalAnalysisforSemiCompRisks")
library(CausalAnalysisforSemiCompRisks)
rm(list  = ls())
load(file = "data/REVEAL_HBV.rda")
simulation(1, 'null', repeat_size = 100)
